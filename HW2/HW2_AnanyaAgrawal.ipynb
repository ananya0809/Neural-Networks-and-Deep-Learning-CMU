{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tQ8UHKRQ61ss"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.src.legacy.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import VGG16\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from keras.applications import EfficientNetB0\n",
    "from keras.applications import ResNet50\n",
    "from keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "z8_Bc5iTl0r4"
   },
   "outputs": [],
   "source": [
    "# Step 1: Extract the dataset\n",
    "extracted_path = 'dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "JQKoKRg27mQf"
   },
   "outputs": [],
   "source": [
    "# Step 2: Load and split the dataset\n",
    "image_size = (128, 128)\n",
    "batch_size = 32\n",
    "\n",
    "train_csv_path = os.path.join(extracted_path, 'train_data.csv')\n",
    "train_image_dir = os.path.join(extracted_path, 'train_images')\n",
    "\n",
    "test_image_dir = os.path.join(extracted_path, 'test_images')\n",
    "\n",
    "test_filenames = os.listdir(test_image_dir)\n",
    "test_df = pd.DataFrame({'img_name': test_filenames})\n",
    "\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "train_df.columns = train_df.columns.str.strip().str.lower()\n",
    "train_df.rename(columns={'img_name': 'img_name', 'label': 'label'}, inplace=True)\n",
    "train_df['label'] = train_df['label'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "2x9LiMkIkbd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17636 validated image filenames belonging to 2 classes.\n",
      "Found 4410 validated image filenames belonging to 2 classes.\n",
      "Found 5512 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# Split into training and validation sets\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Use ImageDataGenerator for data augmentation and normalization\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=train_image_dir,\n",
    "    x_col='img_name',\n",
    "    y_col='label',\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    directory=train_image_dir,\n",
    "    x_col='img_name',\n",
    "    y_col='label',\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory=test_image_dir,\n",
    "    x_col='img_name',\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Build a CNN model with EfficientNetB0\n",
    "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "base_model.trainable = False  # Freeze the base model layers for transfer learning\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 1us/step\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Build a CNN model with ResNet50\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "base_model.trainable = False  # Freeze the base model layers for transfer learning\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "eZnVXIcF8K2p"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/ML/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Build the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "B0RWxY_S8OVK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Build a model using a pre-trained network\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "icZOMuoK8N_n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 314ms/step - accuracy: 0.5221 - loss: 0.6923 - val_accuracy: 0.5100 - val_loss: 0.6830\n",
      "Epoch 2/20\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 306ms/step - accuracy: 0.5455 - loss: 0.6863 - val_accuracy: 0.6297 - val_loss: 0.6713\n",
      "Epoch 3/20\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 303ms/step - accuracy: 0.5519 - loss: 0.6842 - val_accuracy: 0.6429 - val_loss: 0.6669\n",
      "Epoch 4/20\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 299ms/step - accuracy: 0.5693 - loss: 0.6814 - val_accuracy: 0.5612 - val_loss: 0.6684\n",
      "Epoch 5/20\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 297ms/step - accuracy: 0.5705 - loss: 0.6795 - val_accuracy: 0.5431 - val_loss: 0.6704\n",
      "Epoch 6/20\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 301ms/step - accuracy: 0.5847 - loss: 0.6782 - val_accuracy: 0.5549 - val_loss: 0.6645\n",
      "Epoch 7/20\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 297ms/step - accuracy: 0.5844 - loss: 0.6753 - val_accuracy: 0.5483 - val_loss: 0.6664\n",
      "Epoch 8/20\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m590s\u001b[0m 1s/step - accuracy: 0.5911 - loss: 0.6743 - val_accuracy: 0.5381 - val_loss: 0.6726\n",
      "Epoch 9/20\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 304ms/step - accuracy: 0.5908 - loss: 0.6711 - val_accuracy: 0.5642 - val_loss: 0.6607\n",
      "Epoch 10/20\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 303ms/step - accuracy: 0.5942 - loss: 0.6709 - val_accuracy: 0.5422 - val_loss: 0.6720\n",
      "Epoch 11/20\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 303ms/step - accuracy: 0.5993 - loss: 0.6689 - val_accuracy: 0.5683 - val_loss: 0.6584\n",
      "Epoch 12/20\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 301ms/step - accuracy: 0.5978 - loss: 0.6669 - val_accuracy: 0.5399 - val_loss: 0.6779\n",
      "Epoch 13/20\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 302ms/step - accuracy: 0.5987 - loss: 0.6669 - val_accuracy: 0.5773 - val_loss: 0.6559\n",
      "Epoch 14/20\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 301ms/step - accuracy: 0.6063 - loss: 0.6643 - val_accuracy: 0.5773 - val_loss: 0.6565\n",
      "Epoch 15/20\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 633ms/step - accuracy: 0.6064 - loss: 0.6631 - val_accuracy: 0.6177 - val_loss: 0.6431\n",
      "Epoch 16/20\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 315ms/step - accuracy: 0.6065 - loss: 0.6605 - val_accuracy: 0.5576 - val_loss: 0.6669\n",
      "Epoch 17/20\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 302ms/step - accuracy: 0.6179 - loss: 0.6571 - val_accuracy: 0.5556 - val_loss: 0.6724\n",
      "Epoch 18/20\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 304ms/step - accuracy: 0.6102 - loss: 0.6603 - val_accuracy: 0.5601 - val_loss: 0.6692\n",
      "Epoch 19/20\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 306ms/step - accuracy: 0.6054 - loss: 0.6604 - val_accuracy: 0.5989 - val_loss: 0.6482\n",
      "Epoch 20/20\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 305ms/step - accuracy: 0.6152 - loss: 0.6563 - val_accuracy: 0.5653 - val_loss: 0.6661\n",
      "Model training complete!\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=20,\n",
    "    validation_data=val_generator\n",
    ")\n",
    "\n",
    "print(\"Model training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to dataset/malaria_detection_model.h5\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model_save_path = os.path.join(extracted_path, 'malaria_detection_model.h5')\n",
    "model.save(model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "# Load the model for prediction\n",
    "model = load_model(\"dataset/malaria_detection_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Make predictions on the test set\n",
    "predictions = model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8EIfelIG8m_I"
   },
   "outputs": [],
   "source": [
    "# Step 6: Create a submission CSV\n",
    "test_df['label'] = predictions.flatten()\n",
    "test_df['label'] = (test_df['label'] > 0.5).astype(int)\n",
    "\n",
    "submission_path = os.path.join(extracted_path, 'test_data.csv')\n",
    "test_df.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"Test predictions saved to {submission_path}!\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
