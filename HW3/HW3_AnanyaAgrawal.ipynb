{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ananya Agrawal (ananyaa2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchmetrics\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from lightning import LightningModule, Trainer\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "import pickle\n",
    "from sklearn.manifold import TSNE\n",
    "import umap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configuration\n",
    "MODEL_NAME = \"Rostlab/prot_bert\"\n",
    "BATCH_SIZE = 32  \n",
    "EPOCHS = 50\n",
    "DATA_DIR = \"datafiles\"\n",
    "NUM_WORKERS = 8\n",
    "\n",
    "# Device Handling\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "# Load Data\n",
    "train_df = pd.read_csv(os.path.join(DATA_DIR, \"train_data.csv\"))\n",
    "val_df = pd.read_csv(os.path.join(DATA_DIR, \"val_data.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(DATA_DIR, \"test_data.csv\"))\n",
    "classes = pickle.load(open(os.path.join(DATA_DIR, \"selected_families.pkl\"), \"rb\"))\n",
    "cls2idx = {cls: idx for idx, cls in enumerate(classes)}\n",
    "\n",
    "def preprocess_sequence(seq):\n",
    "    return seq.replace(\"X\", \"\").replace(\"U\", \"\").replace(\"B\", \"\").replace(\"O\", \"\").replace(\"Z\", \"\")\n",
    "\n",
    "# Dataset Class\n",
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, df, with_labels=True):\n",
    "        self.sequences = df[\"sequence\"].apply(preprocess_sequence).values\n",
    "        self.labels = df[\"family_id\"].map(cls2idx).values if with_labels else None\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, do_lower_case=False)\n",
    "        self.with_labels = with_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encoding = self.tokenizer(self.sequences[idx], padding=\"max_length\", truncation=True, max_length=256, return_tensors=\"pt\")\n",
    "        input_ids = encoding[\"input_ids\"].squeeze(0)\n",
    "        attention_mask = encoding[\"attention_mask\"].squeeze(0)\n",
    "        if self.with_labels:\n",
    "            label = torch.tensor(self.labels[idx])\n",
    "            return input_ids, attention_mask, label\n",
    "        return input_ids, attention_mask\n",
    "\n",
    "# Data Loaders\n",
    "train_loader = DataLoader(ProteinDataset(train_df), batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "val_loader = DataLoader(ProteinDataset(val_df), batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "test_loader = DataLoader(ProteinDataset(test_df, with_labels=False), batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "# Model Definition\n",
    "class ProteinClassifier(LightningModule):\n",
    "    def __init__(self, n_classes=len(classes)):\n",
    "        super().__init__()\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=n_classes)\n",
    "        self.model.gradient_checkpointing_enable()\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=n_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        return outputs.logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids, attention_mask, labels = input_ids.to(self.device), attention_mask.to(self.device), labels.to(self.device)\n",
    "        logits = self(input_ids, attention_mask)\n",
    "        loss = self.criterion(logits, labels)\n",
    "        acc = self.accuracy(logits.softmax(dim=1), labels)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        self.log(\"train_acc\", acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids, attention_mask, labels = input_ids.to(self.device), attention_mask.to(self.device), labels.to(self.device)\n",
    "        logits = self(input_ids, attention_mask)\n",
    "        loss = self.criterion(logits, labels)\n",
    "        acc = self.accuracy(logits.softmax(dim=1), labels)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=2e-5)\n",
    "\n",
    "# Training\n",
    "model = ProteinClassifier()\n",
    "trainer = Trainer(max_epochs=EPOCHS, callbacks=[ModelCheckpoint(monitor=\"val_acc\", mode=\"max\")], accumulate_grad_batches=2, accelerator=\"gpu\" if torch.cuda.is_available() else \"auto\")\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "# Inference\n",
    "model.eval()\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for input_ids, attention_mask in test_loader:\n",
    "        input_ids, attention_mask = input_ids.to(model.device), attention_mask.to(model.device)\n",
    "        logits = model(input_ids, attention_mask)\n",
    "        preds = logits.argmax(dim=1).cpu().numpy()\n",
    "        predictions.extend(preds)\n",
    "\n",
    "# Create submission file\n",
    "submission = pd.read_csv(os.path.join(DATA_DIR, \"sample_submission.csv\"))\n",
    "submission[\"family_id\"] = [classes[p] for p in predictions]\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "# UMAP Visualization\n",
    "embeddings = []\n",
    "labels = []\n",
    "with torch.no_grad():\n",
    "    for input_ids, attention_mask, label in train_loader:\n",
    "        input_ids, attention_mask = input_ids.to(model.device), attention_mask.to(model.device)\n",
    "        embs = model.model.base_model(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state[:, 0, :].cpu().numpy()\n",
    "        embeddings.extend(embs)\n",
    "        labels.extend(label.cpu().numpy())\n",
    "\n",
    "embeddings = np.array(embeddings)\n",
    "labels = np.array(labels)\n",
    "\n",
    "reducer = umap.UMAP(n_components=2)\n",
    "umap_embeddings = reducer.fit_transform(embeddings)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(umap_embeddings[:, 0], umap_embeddings[:, 1], c=labels, cmap='viridis', alpha=0.6)\n",
    "plt.colorbar()\n",
    "plt.title(\"Protein Embeddings - UMAP Visualization\")\n",
    "plt.savefig(\"umap_visualization.png\")\n",
    "plt.close()\n",
    "\n",
    "# Accuracy plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(label=\"Train Accuracy\")\n",
    "plt.plot(label=\"Validation Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training and Validation Accuracy Over Epochs (Simulated)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"accuracy_plot_real_data_simulated.png\")\n",
    "plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
